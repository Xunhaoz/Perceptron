{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:29.592071Z",
     "start_time": "2024-06-03T01:22:25.480178600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ],
   "id": "ccd9302589ec9722",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:29.597750400Z",
     "start_time": "2024-06-03T01:22:29.581269400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(72)"
   ],
   "id": "f34abc72fb02eb78",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:29.672135100Z",
     "start_time": "2024-06-03T01:22:29.611076600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_image(path=\"ORL3232\", category=10):\n",
    "    def one_hot(x):\n",
    "        z = np.zeros(category)\n",
    "        z[x - 1] = 1\n",
    "        return z\n",
    "\n",
    "    bmps = Path(path).rglob(\"*.bmp\")\n",
    "    data = {\"labels\": [], \"ids\": [], \"images\": []}\n",
    "\n",
    "    for bmp in bmps:\n",
    "        if not bmp.parent.stem.isdigit():\n",
    "            continue\n",
    "\n",
    "        if not int(bmp.parent.stem) <= 10:\n",
    "            continue\n",
    "\n",
    "        data[\"labels\"].append(int(bmp.parent.stem))\n",
    "        data[\"ids\"].append(int(bmp.stem))\n",
    "        data[\"images\"].append(cv2.imread(str(bmp))[:, :, 0].squeeze().flatten())\n",
    "\n",
    "    dataframe = pd.DataFrame(data).sample(frac=1)\n",
    "    dataframe['labels_onehot'] = dataframe['labels'].apply(lambda x: one_hot(x))\n",
    "\n",
    "    train = dataframe[dataframe['ids'] % 2 == 1]\n",
    "    test = dataframe[dataframe['ids'] % 2 == 0]\n",
    "\n",
    "    images = np.stack(train['images'].tolist() + test['images'].tolist())\n",
    "    labels = np.stack(train['labels'].tolist() + test['labels'].tolist())\n",
    "    labels_onehot = np.stack(train['labels_onehot'].tolist() + test['labels_onehot'].tolist())\n",
    "\n",
    "    return images, labels, labels_onehot"
   ],
   "id": "96c20ba90b65a9c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:29.723793300Z",
     "start_time": "2024-06-03T01:22:29.646880200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pca(data, n_components):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data_normalized = (data - mean) / std\n",
    "    cov_matrix = np.cov(data_normalized, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "    sorted_index = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_index]\n",
    "    feature_vectors = sorted_eigenvectors[:, :n_components]\n",
    "    pca_data = np.dot(data_normalized, feature_vectors)\n",
    "    return pca_data\n",
    "\n",
    "\n",
    "def lda(X, y, num_components=2):\n",
    "    class_labels = np.unique(y)\n",
    "    mean_overall = np.mean(X, axis=0)\n",
    "    S_W = np.zeros((X.shape[1], X.shape[1]))\n",
    "    S_B = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for c in class_labels:\n",
    "        X_c = X[y == c]\n",
    "        mean_c = np.mean(X_c, axis=0)\n",
    "        S_W += np.dot((X_c - mean_c).T, (X_c - mean_c))\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_diff = (mean_c - mean_overall).reshape(-1, 1)\n",
    "        S_B += n_c * np.dot(mean_diff, mean_diff.T)\n",
    "    A = np.dot(np.linalg.inv(S_W), S_B)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "    eigenvectors = eigenvectors[:, np.argsort(eigenvalues)[::-1]]\n",
    "    W = eigenvectors[:, :num_components]\n",
    "    return np.real(W)\n",
    "\n",
    "\n",
    "def euclidean_similarity(A, B):\n",
    "    A = A[:, np.newaxis, :]\n",
    "    B = B[np.newaxis, :, :]\n",
    "    distances = np.sqrt(np.sum((A - B) ** 2, axis=2))\n",
    "    similarity = 1 / (1 + distances)\n",
    "    return similarity"
   ],
   "id": "60f9affebc4ad065",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:29.784708700Z",
     "start_time": "2024-06-03T01:22:29.667926700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(data):\n",
    "    data = data / 255\n",
    "    return data\n",
    "\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    return data"
   ],
   "id": "622b677e00a2987f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:33.858356500Z",
     "start_time": "2024-06-03T01:22:29.711088800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images, labels, labels_onehot = read_image()\n",
    "images = min_max_normalize(images)\n",
    "convert_matrix = lda(images, labels, 2)\n",
    "images = np.dot(images, convert_matrix)"
   ],
   "id": "55e69216341954a8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:33.873810600Z",
     "start_time": "2024-06-03T01:22:33.862774100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images, test_images = images[:50, :], images[50:, :]\n",
    "train_labels_onehot, test_labels_onehot = labels_onehot[:50, :], labels_onehot[50:, :]\n",
    "train_labels, test_labels = labels[:200], labels[200:]"
   ],
   "id": "7c8cd2cc8e9bcfd2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def levenberg_marquardt(cost_func, x0, args=(), max_iter=100, lambda_=0.01, up_factor=10, down_factor=9, tol=1e-6):\n",
    "    x = x0.copy()\n",
    "    for i in range(max_iter):\n",
    "        residuals = cost_func(x, *args)\n",
    "        cost = 0.5 * np.sum(residuals**2)\n",
    "\n",
    "        # 计算雅可比矩阵\n",
    "        J = approx_jacobian(x, cost_func, residuals, *args)\n",
    "\n",
    "        # 计算梯度\n",
    "        gradient = J.T @ residuals\n",
    "\n",
    "        # 计算 Hessian 矩阵的近似\n",
    "        A = J.T @ J\n",
    "\n",
    "        # 调整阻尼因子\n",
    "        eye = np.eye(len(x))\n",
    "        while True:\n",
    "            # 解更新方程（带阻尼的高斯-牛顿方程）\n",
    "            delta = np.linalg.solve(A + lambda_ * eye, -gradient)\n",
    "            new_x = x + delta\n",
    "            new_residuals = cost_func(new_x, *args)\n",
    "            new_cost = 0.5 * np.sum(new_residuals**2)\n",
    "\n",
    "            # 检查是否改善\n",
    "            if new_cost < cost:\n",
    "                # 成功，减小阻尼因子\n",
    "                lambda_ /= down_factor\n",
    "                x = new_x\n",
    "                if np.linalg.norm(delta) < tol:\n",
    "                    break\n",
    "                break\n",
    "            else:\n",
    "                # 失败，增大阻尼因子\n",
    "                lambda_ *= up_factor\n",
    "\n",
    "    return x\n",
    "\n",
    "def approx_jacobian(x, func, f0, *args, eps=1e-8):\n",
    "    jacobian = np.zeros((len(f0), len(x)))\n",
    "    for i in range(len(x)):\n",
    "        dx = np.zeros_like(x)\n",
    "        dx[i] = eps\n",
    "        fi = func(x + dx, *args)\n",
    "        jacobian[:, i] = (fi - f0) / eps\n",
    "    return jacobian\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:33.917634500Z",
     "start_time": "2024-06-03T01:22:33.885361100Z"
    }
   },
   "id": "e1c42bd401ae0101"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-6.04481242e+00, -1.74213171e+00,  2.06429148e+00,  4.01488121e+01,\n        1.10103336e+01, -5.27232162e+00, -7.57947734e+00, -2.97430273e+01,\n       -2.67951756e-02,  2.72129486e+01,  9.76645817e+00, -2.40937854e+00,\n       -2.67312310e+01,  1.47694032e+01,  2.60488236e+00,  8.85964782e+00,\n        1.35373950e+01, -1.02262029e+00, -2.71178517e+01,  3.02802421e+01,\n        5.47891071e+00, -2.03087941e+01, -1.45164102e+01,  2.18269281e+00,\n        1.10893160e+00, -2.26913025e+01, -1.18746253e+01, -1.50313236e+01,\n        1.72920135e+01, -4.08898340e+00,  1.67759590e+01,  4.32274768e+00,\n       -6.22829471e+00, -7.19624563e+00,  2.94398490e+01, -8.83290588e+00,\n        1.81886237e+01, -2.05333114e+01,  4.59874629e+00, -1.60188272e+01,\n       -1.59860016e+01, -3.67745440e+00,  2.33939507e+00, -1.81261314e+01,\n        2.43297253e+01, -1.35161137e+01, -6.22839634e+00, -1.22937789e+01,\n       -1.52309135e+01,  1.65263873e+01,  5.50195833e+00,  1.64789077e-01,\n       -5.57112680e+00,  1.95302559e+00, -8.07658399e-01, -5.64456191e+00,\n       -1.18587952e+00,  1.62358260e+00, -1.11307553e+00,  6.12737283e-01,\n       -3.45471331e+00, -2.75480278e+00, -8.18336129e+00,  5.13981724e+00,\n       -3.36665029e+00,  3.06694110e+00,  1.20506913e+01, -7.29036476e+00,\n       -3.35300650e+00,  7.57099351e-01,  3.58035276e+00, -6.60851990e-01,\n        3.39601397e+00, -4.40671028e+00, -2.13744021e+00, -5.45601310e+00,\n       -1.77004511e+00, -1.07744541e-02, -3.19510592e+00,  3.88374118e+00,\n       -1.47093533e+01,  5.56574934e+00, -6.02683613e+00,  4.92064392e+00,\n        1.45637283e+01, -9.79514123e+00, -3.87970707e+00,  1.07013128e-01,\n       -1.30194548e+00,  8.78597202e-01,  2.32517590e+00, -4.89765406e+00,\n       -7.12150203e-01, -2.89896385e+00, -4.48463885e-01, -1.86807831e-01,\n       -2.01530406e+00, -4.42551876e+00, -4.92445791e+00,  2.63249287e+00,\n       -1.27962130e+00, -3.16510189e-01,  7.67138911e+00, -2.93030721e+00,\n       -2.06990187e+00,  4.44168935e-01, -1.90021759e+00,  5.37250159e+00,\n       -4.91600516e-01, -4.16364739e+00, -2.71679128e+00, -4.21098837e+00,\n        2.43428354e+00, -4.18543187e-01])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    x_clipped = np.clip(x, -20, 20)\n",
    "    return np.where(x_clipped >= 0, 1 / (1 + np.exp(-x_clipped)), np.exp(x_clipped) / (1 + np.exp(x_clipped)))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "input_size = 2  \n",
    "hidden_size = 8  \n",
    "output_size = 10  \n",
    "\n",
    "def cost_function(weights, X, y):\n",
    "    split = hidden_size * (input_size + 1)\n",
    "    hidden_weights = weights[:split].reshape((hidden_size, input_size + 1))\n",
    "    output_weights = weights[split:].reshape((output_size, hidden_size + 1))\n",
    "\n",
    "    hidden_layer_input = np.dot(X, hidden_weights[:, :-1].T) + hidden_weights[:, -1]\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, output_weights[:, :-1].T) + output_weights[:, -1]\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "    residuals = output_layer_output.ravel() - y.ravel()\n",
    "    return residuals.ravel()\n",
    "\n",
    "\n",
    "def predict(weights, X):\n",
    "    split = hidden_size * (input_size + 1)\n",
    "    hidden_weights = weights[:split].reshape((hidden_size, input_size + 1))\n",
    "    output_weights = weights[split:].reshape((output_size, hidden_size + 1))\n",
    "\n",
    "    hidden_layer_input = np.dot(X, hidden_weights[:, :-1].T) + hidden_weights[:, -1]\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, output_weights[:, :-1].T) + output_weights[:, -1]\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "    return output_layer_output\n",
    "\n",
    "initial_weights = np.random.randn(hidden_size * (input_size + 1) + output_size * (hidden_size + 1))\n",
    "result = levenberg_marquardt(cost_function, initial_weights, args=(train_images, train_labels_onehot))\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:52.447575800Z",
     "start_time": "2024-06-03T01:22:33.920635Z"
    }
   },
   "id": "b9bf6564d42d6017"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(result, test_images)\n",
    "np.average(np.argmax(pred, axis=1) == np.argmax(test_labels_onehot, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:52.448580300Z",
     "start_time": "2024-06-03T01:22:52.394989500Z"
    }
   },
   "id": "4e3365195fce16f5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:52.448580300Z",
     "start_time": "2024-06-03T01:22:52.409104400Z"
    }
   },
   "id": "1091b65dcfe4cbfc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T01:22:52.449579800Z",
     "start_time": "2024-06-03T01:22:52.426201300Z"
    }
   },
   "id": "f3d407251fdf59a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
